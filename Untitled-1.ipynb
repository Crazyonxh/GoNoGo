{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit (windows store)"
  },
  "interpreter": {
   "hash": "7885a5acde952479a72a2cdb51138bc727b4d0987c5af3e4c8931535798e4e11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"“trainNeuron.ipynb”的副本\n",
    "\n",
    "Automatically generated by Colaboratory.\n",
    "\n",
    "Original file is located at\n",
    "    https://colab.research.google.com/drive/1bGT0UK8zyHOFnyb6GPftYMM7L_DBJGru\n",
    "\"\"\"\n",
    "\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/gdrive')\n",
    "\"\"\"\n",
    "def random_shuffle(data,label):\n",
    "  dataset=np.hstack([data,label]) \n",
    "  np.random.seed(12345)\n",
    "  np.random.shuffle(dataset)    \n",
    "  return dataset[:,:-1],dataset[:,-1]\n",
    "\"\"\"\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import cv2\n",
    "import os\n",
    "'''\n",
    "train_images = mnist.train_images()\n",
    "train_labels = mnist.train_labels()\n",
    "test_images = mnist.test_images()\n",
    "test_labels = mnist.test_labels()\n",
    "'''\n",
    "array_of_background = [] # this if for store all of the image data\n",
    "array_of_neuron=[]\n",
    "directory_name=\"C:/Users/BBNC/Desktop/DL/neuronDL/background\"\n",
    "directory_name2=\"C:/Users/BBNC/Desktop/DL/neuronDL/neuron\"\n",
    "\n",
    "for filename in os.listdir(directory_name):\n",
    "    img = cv2.imread(directory_name + \"/\" + filename,0)\n",
    "    array_of_background.append(img)\n",
    "    array_of_background.append(img)\n",
    "    array_of_background.append(img)\n",
    "    array_of_background.append(img)\n",
    "    array_of_background.append(img)\n",
    "\n",
    "\n",
    "for filename in os.listdir(directory_name2):\n",
    "    img = cv2.imread(directory_name2 + \"/\" + filename,0)\n",
    "    array_of_neuron.append(img)\n",
    "\n",
    "#myDataset=tf.keras.preprocessing.image_dataset_from_directory(\"/content/gdrive/MyDrive/Colab Notebooks/neuronDL\",color_mode=\"grayscale\", image_size=(32,32),labels='inferred')\n",
    "#myIMG=cv2.imread(\"/content/gdrive/MyDrive/Colab Notebooks/neuronDL/background/1.png\",0)\n",
    "#myIMGArray=tf.keras.preprocessing.image.img_to_array(myIMG)\n",
    "\n",
    "label_of_neuron=np.ones(np.shape(array_of_neuron)[0])\n",
    "label_of_background=np.zeros(np.shape(array_of_background)[0])\n",
    "myData=np.concatenate((array_of_background,array_of_neuron),axis = 0)\n",
    "myLabel=np.concatenate((label_of_background,label_of_neuron),axis = 0)\n",
    "\n",
    "np.shape(myData)\n",
    "np.shape(myLabel)\n",
    "\n",
    "randnum = np.random.randint(0, 1234)\n",
    "np.random.seed(randnum)\n",
    "np.random.shuffle(myData)\n",
    "np.random.seed(randnum)\n",
    "np.random.shuffle(myLabel)\n",
    "train_images=myData[:-100]\n",
    "test_images=myData[-100:-1]\n",
    "train_labels=myLabel[:-100]\n",
    "test_labels=myLabel[-100:-1]\n",
    "\n",
    "# The full CNN code!\n",
    "####################\n",
    "\n",
    "\n",
    "# Normalize the images.\n",
    "train_images = (train_images / 255)\n",
    "test_images = (test_images / 255)\n",
    "\n",
    "# Reshape the images.\n",
    "train_images = np.expand_dims(train_images, axis=3)\n",
    "test_images = np.expand_dims(test_images, axis=3)\n",
    "\n",
    "num_filters = 5\n",
    "filter_size = 3\n",
    "pool_size = 2\n",
    "\n",
    "# Build the model.\n",
    "model = Sequential([\n",
    "  Conv2D(5, filter_size,activation='relu',input_shape=(32,32,1)),\n",
    "  MaxPooling2D(pool_size=3),\n",
    "  Conv2D(5, filter_size,activation='relu'),\n",
    "  MaxPooling2D(pool_size=2),\n",
    "  Conv2D(10, filter_size,activation='relu'),\n",
    "  MaxPooling2D(pool_size=2),\n",
    "  Flatten(),\n",
    "  Dense(2, activation='softmax'),\n",
    "])\n",
    "\n",
    "# Compile the model.\n",
    "model.compile(\n",
    "  'adam',\n",
    "  loss='categorical_crossentropy',\n",
    "  metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "import tensorflow as tf\n",
    "#tf.keras.utils.plot_model(model, to_file='model3.png', show_shapes=True, show_layer_names=True,rankdir='TB', dpi=900, expand_nested=True)\n",
    "\n",
    "to_categorical(test_labels).shape\n",
    "\n",
    "train_images.shape\n",
    "\n",
    "# Train the model.\n",
    "model.fit(  train_images,  to_categorical(train_labels),  epochs=30,  validation_data=(test_images, to_categorical(test_labels)),\n",
    ")\n",
    "\n",
    "# Save the model to disk.\n",
    "model.save_weights('cnn.h5')\n",
    "\n",
    "# Load the model from disk later using:\n",
    "# model.load_weights('cnn.h5')\n",
    "\n",
    "# Predict on the first 5 test images.\n",
    "predictions = model.predict(test_images[:5])\n",
    "\n",
    "# Print our model's predictions.\n",
    "print(np.argmax(predictions, axis=1)) # [7, 2, 1, 0, 4]\n",
    "\n",
    "# Check our predictions against the ground truths.\n",
    "print(test_labels[:5]) # [7, 2, 1, 0, 4]\n",
    "\n",
    "#from google.colab.patches import cv2_imshow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/BBNC/Desktop/DL/neuronDLResult/tf_model_savedmodel\\assets\n",
      "[[0.03821584 0.9617841 ]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\"\"\"ind=58\n",
    "#cv2.imshow((' ',test_images[ind]+0.5)*255)\n",
    "print(test_labels[ind])\n",
    "model.predict(test_images[ind:ind+1])\n",
    "\"\"\"\n",
    "#model.save(\"/content/gdrive/MyDrive/Colab Notebooks/neuronDLResult/\" + 'model')\n",
    "\n",
    "model.save_weights('C:/Users/BBNC/Desktop/DL/neuronDLResult/tf_model_weights.ckpt',save_format = \"tf\")\n",
    "model.save('C:/Users/BBNC/Desktop/DL/neuronDLResult/tf_model_savedmodel', save_format=\"tf\")\n",
    "#model_loaded = tf.keras.models.load_model('content/gdrive/MyDrive/Colab Notebooks/neuronDLResult/tf_model_savedmodel')\n",
    "#model_loaded.evaluate(x_test,y_test)\n",
    "\n",
    "\n",
    "#m =  tf.loadLayersModel(\"/content/gdrive/MyDrive/Colab Notebooks/neuronDLResult/\" + 'model');\n",
    "\"\"\"\n",
    "model_loaded = tf.keras.models.load_model('content/gdrive/MyDrive/Colab Notebooks/neuronDLResult/tf_model_savedmodel')\n",
    "model_loaded.evaluate(test_images[25:79])\n",
    "\n",
    "model_loaded.summary()\n",
    "\n",
    "weight_Dense_0,bias_Dense_0 = model.get_layer('max_pooling2d ').get_weights()\n",
    "weight_Dense_1,bias_Dense_1 = model_loaded.get_layer('max_pooling2d ').get_weights()\n",
    "print(bias_Dense_0)\n",
    "print(bias_Dense_1)\n",
    "\n",
    "model_loaded.predict(test_images[25:26])\n",
    "\"\"\"\n",
    "img = cv2.imread(\"C:/Users/BBNC/Desktop/STD_0112-7.png\",0)\n",
    "\n",
    "img2=np.expand_dims(img, axis=0)\n",
    "img3=np.expand_dims(img2, axis=3)\n",
    "img3.shape\n",
    "print(model.predict((img3/ 255)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-b47f4b5baed9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel_loaded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'C:/Users/BBNC/Desktop/DL/neuronDLResult/tf_model_savedmodel'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mmodel_loaded\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_loaded\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m25\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m26\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import cv2\n",
    "import os\n",
    "model_loaded = tf.keras.models.load_model('C:/Users/BBNC/Desktop/DL/neuronDLResult/tf_model_savedmodel')\n",
    "model_loaded.summary()\n",
    "print(model_loaded.predict(test_images[25:26]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}